{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623de22c-2350-44ed-86f7-086193c58fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilybates/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/emilybates/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for 'Technology-related': 0.013781254838923784\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "file_path_annotator1 = 'Annotation_Predictors.csv'\n",
    "file_path_annotator2 = 'Annotation_Avengers.csv'\n",
    "annotator1_data = pd.read_csv(file_path_annotator1)\n",
    "annotator2_data = pd.read_csv(file_path_annotator2)\n",
    "\n",
    "annotator1_labels = annotator1_data['Technology-related']\n",
    "annotator2_labels = annotator2_data['Technology-related']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels, annotator2_labels)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Technology-related': {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6205fbe2-98a0-4dcf-b540-9741e5d25318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for 'Cost': 0.22097696570528136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "file_path_annotator1 = 'Annotation_Predictors.csv'\n",
    "file_path_annotator2 = 'Annotation_Avengers.csv'\n",
    "\n",
    "annotator1_data = pd.read_csv(file_path_annotator1)\n",
    "annotator2_data = pd.read_csv(file_path_annotator2)\n",
    "\n",
    "annotator1_labels = annotator1_data['Cost']\n",
    "annotator2_labels = annotator2_data['Cost']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels, annotator2_labels)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Cost': {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a9fe46a-0c07-4e85-a5f3-ba8c968a9a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for 'Speed': 0.0541946467417006\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "file_path_annotator1 = 'Annotation_Predictors.csv'\n",
    "file_path_annotator2 = 'Annotation_Avengers.csv'\n",
    "\n",
    "annotator1_data = pd.read_csv(file_path_annotator1)\n",
    "annotator2_data = pd.read_csv(file_path_annotator2)\n",
    "\n",
    "annotator1_labels = annotator1_data['Speed']\n",
    "annotator2_labels = annotator2_data['Speed']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels, annotator2_labels)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Speed': {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0120b6-1c9f-489f-b124-12b6a652de92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for 'Accessibility': 0.04101995565410199\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "file_path_annotator1 = 'Annotation_Predictors.csv'\n",
    "file_path_annotator2 = 'Annotation_Avengers.csv'\n",
    "\n",
    "annotator1_data = pd.read_csv(file_path_annotator1)\n",
    "annotator2_data = pd.read_csv(file_path_annotator2)\n",
    "\n",
    "annotator1_labels = annotator1_data['Accessability']\n",
    "annotator2_labels = annotator2_data['Accessability']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels, annotator2_labels)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Accessibility': {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0224d985-48d4-4cae-b11e-f15562cf2c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for 'Other': -0.005963929007688495\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "file_path_annotator1 = 'Annotation_Predictors.csv'\n",
    "file_path_annotator2 = 'Annotation_Avengers.csv'\n",
    "\n",
    "annotator1_data = pd.read_csv(file_path_annotator1)\n",
    "annotator2_data = pd.read_csv(file_path_annotator2)\n",
    "\n",
    "annotator1_labels = annotator1_data['Other']\n",
    "annotator2_labels = annotator2_data['Other']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels, annotator2_labels)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Other': {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72891ef-2846-40c9-a0f0-e654994fdab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Predictors vs. Gold Standard Annotation:\n",
      "\n",
      "Cohen's Kappa for 'Technology-related': 0.6225136915304315\n",
      "Cohen's Kappa for 'Cost': 0.5610514698505067\n",
      "Cohen's Kappa for 'Speed': 0.6635050158783571\n",
      "Cohen's Kappa for 'Accessibility': 0.3659420289855072\n",
      "Cohen's Kappa for 'Other': 0.4959390342533633\n"
     ]
    }
   ],
   "source": [
    "#comparing Predictors vs Gold Standard\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "print(\"The Predictors vs. Gold Standard Annotation:\")\n",
    "print()\n",
    "\n",
    "file_path_annotator1 = 'Annotation_Predictors.csv'\n",
    "file_path_gs = 'Annotation_Gold_Standard.csv'\n",
    "annotator1_data = pd.read_csv(file_path_annotator1)\n",
    "annotation_gold_standard = pd.read_csv(file_path_gs)\n",
    "\n",
    "annotator1_labels_tech = annotator1_data['Technology-related']\n",
    "gold_standard_labels_tech = annotation_gold_standard['Technology-related']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_tech, gold_standard_labels_tech)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Technology-related': {kappa_score}\")\n",
    "\n",
    "annotator1_labels_cost = annotator1_data['Cost']\n",
    "gold_standard_labels_cost = annotation_gold_standard['Cost']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_cost, gold_standard_labels_cost)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Cost': {kappa_score}\")\n",
    "\n",
    "annotator1_labels_speed = annotator1_data['Speed']\n",
    "gold_standard_labels_speed = annotation_gold_standard['Speed']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_speed, gold_standard_labels_speed)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Speed': {kappa_score}\")\n",
    "\n",
    "annotator1_labels_acc = annotator1_data['Accessability']\n",
    "gold_standard_labels_acc = annotation_gold_standard['Accessability']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_acc, gold_standard_labels_acc)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Accessibility': {kappa_score}\")\n",
    "\n",
    "annotator1_labels_other = annotator1_data['Other']\n",
    "gold_standard_labels_other = annotation_gold_standard['Other']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_other, gold_standard_labels_other)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Other': {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d4db16f-0270-4cfd-a529-19fadab971d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Annotation Avengers vs. Gold Standard Annotation:\n",
      "\n",
      "Cohen's Kappa for 'Technology-related': 0.05656522885721815\n",
      "Cohen's Kappa for 'Cost': 0.14064441315331733\n",
      "Cohen's Kappa for 'Speed': 0.05650262678245943\n",
      "Cohen's Kappa for 'Accessibility': 0.07063197026022305\n",
      "Cohen's Kappa for 'Other': 0.005334355014588343\n"
     ]
    }
   ],
   "source": [
    "#comparing Avengers vs Gold Standard\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "print(\"The Annotation Avengers vs. Gold Standard Annotation:\")\n",
    "print()\n",
    "\n",
    "file_path_annotator1 = 'Annotation_Avengers.csv'\n",
    "file_path_gs = 'Annotation_Gold_Standard.csv'\n",
    "annotator1_data = pd.read_csv(file_path_annotator1)\n",
    "annotation_gold_standard = pd.read_csv(file_path_gs)\n",
    "\n",
    "annotator1_labels_tech = annotator1_data['Technology-related']\n",
    "gold_standard_labels_tech = annotation_gold_standard['Technology-related']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_tech, gold_standard_labels_tech)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Technology-related': {kappa_score}\")\n",
    "\n",
    "annotator1_labels_cost = annotator1_data['Cost']\n",
    "gold_standard_labels_cost = annotation_gold_standard['Cost']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_cost, gold_standard_labels_cost)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Cost': {kappa_score}\")\n",
    "\n",
    "annotator1_labels_speed = annotator1_data['Speed']\n",
    "gold_standard_labels_speed = annotation_gold_standard['Speed']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_speed, gold_standard_labels_speed)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Speed': {kappa_score}\")\n",
    "\n",
    "annotator1_labels_acc = annotator1_data['Accessability']\n",
    "gold_standard_labels_acc = annotation_gold_standard['Accessability']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_acc, gold_standard_labels_acc)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Accessibility': {kappa_score}\")\n",
    "\n",
    "annotator1_labels_other = annotator1_data['Other']\n",
    "gold_standard_labels_other = annotation_gold_standard['Other']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator1_labels_other, gold_standard_labels_other)\n",
    "\n",
    "print(f\"Cohen's Kappa for 'Other': {kappa_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c664aad-8d5e-451e-b4b0-54e64850072f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Comment Text  Technology-related  \\\n",
      "0  I think arts, culture, and science should be s...                   1   \n",
      "1  If you wish to stick with iPhone, the iPhone 6...                   1   \n",
      "2  I know, its just harder than I thought living ...                   1   \n",
      "3  I'm really stuck as to where to begin, but I'l...                   0   \n",
      "4  USAA is a great choice. I worked there for two...                   1   \n",
      "\n",
      "   Cost  Speed  Accessability  \n",
      "0     1      0              0  \n",
      "1     1      0              0  \n",
      "2     0      0              1  \n",
      "3     0      0              0  \n",
      "4     0      1              0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Gold Standard Data\n",
    "gold_standard_data = pd.read_csv('Annotation_Gold_Standard.csv')\n",
    "\n",
    "# Initial Preprocessing\n",
    "# Check for and handle missing values (if necessary)\n",
    "gold_standard_data.drop(['Other', 'Annotator Comment'], axis=1, inplace=True) # Example: Remove rows with missing values\n",
    "\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(gold_standard_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da046c87-dc73-40bd-a17d-91ef0cdc5fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LexiconClassifier():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Initalize the Lexicon classifer by loading lexicons. \n",
    "        \"\"\"\n",
    "        self.positive_words = set()\n",
    "        with open('positive-words.txt', encoding = 'utf-8') as iFile:\n",
    "            for row in iFile:\n",
    "                self.positive_words.add(row.strip())\n",
    "\n",
    "        self.negative_words = set()\n",
    "        with open('negative-words.txt', encoding='iso-8859-1') as iFile:\n",
    "            for row in iFile:\n",
    "                self.negative_words.add(row.strip())\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        \"\"\"\n",
    "            Returns a sentiment prediction give an input string.\n",
    "            \n",
    "            Keyword arguments:\n",
    "            sentence -- string (e.g., \"This is good good good\")\n",
    "            \n",
    "            Returns:\n",
    "            pred -- a string (\"postive, \"negative\", or \"neutral\")\n",
    "        \"\"\"\n",
    "        num_pos_words = 0\n",
    "        num_neg_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.positive_words:\n",
    "                num_pos_words += 1\n",
    "            elif word in self.negative_words:\n",
    "                num_neg_words += 1\n",
    "        \n",
    "        pred = 'neutral'        \n",
    "        if num_pos_words > num_neg_words:\n",
    "            pred = 'positive'\n",
    "        elif num_pos_words < num_neg_words:\n",
    "            pred = 'negative'\n",
    "            \n",
    "        return pred\n",
    "    \n",
    "    def count_pos_words(self, sentence):\n",
    "        \"\"\"\n",
    "            Returns the number of positive words in string\n",
    "            \n",
    "            Keyword arguments:\n",
    "            sentence -- string (e.g., \"This is good good good\")\n",
    "            \n",
    "            Returns:\n",
    "            pred -- an integer (e.g., 3)\n",
    "        \"\"\"\n",
    "        num_pos_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.positive_words:\n",
    "                num_pos_words += 1\n",
    "        return num_pos_words\n",
    "\n",
    "    def count_neg_words(self, sentence):\n",
    "        \"\"\"\n",
    "            Returns the number of negative words in string\n",
    "            \n",
    "            Keyword arguments:\n",
    "            sentence -- string (e.g., \"This is good good good\")\n",
    "            \n",
    "            Returns:\n",
    "            pred -- an integer (e.g., 3)\n",
    "        \"\"\"\n",
    "        num_neg_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.negative_words:\n",
    "                num_neg_words += 1\n",
    "        return num_neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c622238-943d-438f-84ea-e7a1766dc272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to count the number of capital words in a text\n",
    "def count_capital_words(text):\n",
    "    return sum(word.isupper() for word in text.split())\n",
    "\n",
    "# Apply the function to the 'Comment Text' column\n",
    "gold_standard_data['capital_word_count'] = gold_standard_data['Comment Text'].apply(count_capital_words)\n",
    "\n",
    "# Function to count the number of exclamation points in a text\n",
    "def count_exclamation_points(text):\n",
    "    return text.count('!')\n",
    "gold_standard_data['exclamation_count'] = gold_standard_data['Comment Text'].apply(count_exclamation_points)\n",
    "\n",
    "lex_classifier = LexiconClassifier()\n",
    "\n",
    "gold_standard_data['positive_word_count'] = gold_standard_data['Comment Text'].apply(lex_classifier.count_pos_words)\n",
    "gold_standard_data['negative_word_count'] = gold_standard_data['Comment Text'].apply(lex_classifier.count_neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4994cd76-a74d-4983-9544-593d6f705b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_text = vectorizer.fit_transform(gold_standard_data['Comment Text'])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_combined = hstack([X_text, gold_standard_data[['capital_word_count', 'exclamation_count', 'positive_word_count', 'negative_word_count']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050de88b-a18a-451f-bc75-9ee7b50b3191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = gold_standard_data[['Technology-related', 'Cost', 'Speed', 'Accessability']]\n",
    "\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(X_combined, y, test_size=0.30, random_state=42)\n",
    "\n",
    "test_size = 0.5 # Since it's half of 30%, this will make 15% of the total for both validation and test\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_remaining, y_remaining, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003d59fc-8ee8-41ab-bc86-6730eb70ed47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "ovr_model = OneVsRestClassifier(LinearSVC())\n",
    "\n",
    "param_grid = {'estimator__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(ovr_model, param_grid, scoring='f1_macro', cv=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_ovr_model = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a2f79d2-0e12-4f54-9f64-42ac8c3e3f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Precision: 0.6505102040816326\n",
      "Validation Recall: 0.27154471544715447\n",
      "Validation F1 Score: 0.31865079365079363\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "y_val_pred = best_ovr_model.predict(X_validate)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision_macro = precision_score(y_validate, y_val_pred, average='macro')\n",
    "recall_macro = recall_score(y_validate, y_val_pred, average='macro')\n",
    "f1_macro = f1_score(y_validate, y_val_pred, average='macro')\n",
    "\n",
    "print(f\"Validation Precision: {precision_macro}\")\n",
    "print(f\"Validation Recall: {recall_macro}\")\n",
    "print(f\"Validation F1 Score: {f1_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b251ff-5849-4881-89fb-fe4e596c3876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Precision: 0.61\n",
      "Validation Recall: 0.6559139784946236\n",
      "Validation F1 Score: 0.6321243523316062\n"
     ]
    }
   ],
   "source": [
    "precision_micro = precision_score(y_validate, y_val_pred, average='micro')\n",
    "recall_micro = recall_score(y_validate, y_val_pred, average='micro')\n",
    "f1_micro = f1_score(y_validate, y_val_pred, average='micro')\n",
    "\n",
    "print(f\"Validation Precision: {precision_micro}\")\n",
    "print(f\"Validation Recall: {recall_micro}\")\n",
    "print(f\"Validation F1 Score: {f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbc8a16d-55e4-4733-80e8-5cf03081d79c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.2648809523809524\n",
      "Test Recall: 0.18368617683686178\n",
      "Test F1 Score: 0.1881430671239588\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_test_pred = best_ovr_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "test_precision_macro = precision_score(y_test, y_test_pred, average='macro')\n",
    "test_recall_macro = recall_score(y_test, y_test_pred, average='macro')\n",
    "test_f1_macro = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(f\"Test Precision: {test_precision_macro}\")\n",
    "print(f\"Test Recall: {test_recall_macro}\")\n",
    "print(f\"Test F1 Score: {test_f1_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a4d019e-e1bf-469b-afe6-924e3003c667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.5454545454545454\n",
      "Test Recall: 0.5106382978723404\n",
      "Test F1 Score: 0.5274725274725275\n"
     ]
    }
   ],
   "source": [
    "test_precision_micro = precision_score(y_test, y_test_pred, average='micro')\n",
    "test_recall_micro = recall_score(y_test, y_test_pred, average='micro')\n",
    "test_f1_micro = f1_score(y_test, y_test_pred, average='micro')\n",
    "\n",
    "print(f\"Test Precision: {test_precision_micro}\")\n",
    "print(f\"Test Recall: {test_recall_micro}\")\n",
    "print(f\"Test F1 Score: {test_f1_micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46ddbc9b-c2f0-44a4-ab59-9c55a7e9ea1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with Comment Text, Gold Label, and Predictions\n",
    "test_results = pd.DataFrame({\n",
    "    'Comment Text': gold_standard_data.loc[y_test.index, 'Comment Text'],\n",
    "    'Gold_Label_Technology': y_test['Technology-related'].values,\n",
    "    'Gold_Label_Cost': y_test['Cost'].values,\n",
    "    'Gold_Label_Speed': y_test['Speed'].values,\n",
    "    'Gold_Label_Accessability': y_test['Accessability'].values,\n",
    "    'Predicted_Technology': y_test_pred[:, 0],\n",
    "    'Predicted_Cost': y_test_pred[:, 1],\n",
    "    'Predicted_Speed': y_test_pred[:, 2],\n",
    "    'Predicted_Accessability': y_test_pred[:, 3],\n",
    "})\n",
    "\n",
    "columns_to_replace = ['Gold_Label_Technology', 'Gold_Label_Cost', 'Gold_Label_Speed', 'Gold_Label_Accessability', \n",
    "                      'Predicted_Technology', 'Predicted_Cost', 'Predicted_Speed', 'Predicted_Accessability']\n",
    "test_results[columns_to_replace] = test_results[columns_to_replace].replace({0: 'No', 1: 'Yes'})\n",
    "\n",
    "# Save the combined results to CSV\n",
    "test_results.to_csv('new_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad05fa-a0c4-468c-819b-0b2fc9dcfb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
